{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_2HaKJJTUHy"
      },
      "source": [
        "# spaCy\n",
        "\n",
        "spaCy es otra librería open source en Python para NLP.\n",
        "\n",
        "La diferencia fundamental entre NLTK y spaCy es que el primero es muy cómodo para aprender e iniciarse mientras que el segundo está pensado para productizar.\n",
        "\n",
        "Gensim, otra librería, la veremos más adelante cuando estudiemos Topic Modeling y Word Embeddings.\n",
        "\n",
        "Documentación de spaCy: https://spacy.io/\n",
        "\n",
        "La filosofía de trabajo en spaCy es que si existen una serie de algoritmos que solucionan un problema, dar la solución al problema con un único. Además, su funcionamiento se basa en la construcción de pipelines.\n",
        "\n",
        "\n",
        "<img src=https://i.imgur.com/nD7ut2U.jpg>\n",
        "\n",
        "¿Qué capacidades (modelos) linguísticas nos ofrece spaCy?\n",
        "\n",
        "<img src=https://i.imgur.com/lGcL6lx.jpg>\n",
        "\n",
        "Es decir, de spaCy podremos sacar siempre que queramos tokens, pos tags, árboles de dependencia, o entidades nombradas. Incluye también modelos de word embeddings (que veremos con más detalle en sesiones posteriores)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IomNqNVLTUH1"
      },
      "source": [
        "<img src=https://spacy.io/architecture-bcdfffe5c0b9f221a2f6607f96ca0e4a.svg width=550px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DFo1vEnTUH1"
      },
      "source": [
        "## Modelos de spaCy\n",
        "\n",
        "Modelos pre-entrenados para diferentes idiomas y con diferentes corpus. Pueden ser descargados de diferentes maneras, tanto descarga directa, como con pip.\n",
        "\n",
        "Link: https://spacy.io/usage/models\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-CowJoZUN6Oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uAL73d9G9gh",
        "outputId": "bc67fe93-7987-4b9e-ec97-759d122955f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy download es_core_news_sm\n",
        "!pip install -U spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "id": "-71CXhu5DTcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fdd340a-251c-4843-d475-1682574c51ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Collecting download\n",
            "  Downloading download-0.3.5-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting es_core_news_sm\n",
            "  Downloading es_core_news_sm-3.1.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from download) (1.17.0)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.1.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Collecting thinc<8.1.0,>=8.0.12 (from spacy)\n",
            "  Downloading thinc-8.0.17.tar.gz (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.7/189.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting blis<0.8.0,>=0.4.0 (from spacy)\n",
            "  Using cached blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting wasabi<1.1.0,>=0.8.1 (from spacy)\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting typer<0.5.0,>=0.3.0 (from spacy)\n",
            "  Downloading typer-0.4.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pathy>=0.3.5 (from spacy)\n",
            "  Downloading pathy-0.11.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting smart-open<7.0.0,>=5.2.1 (from spacy)\n",
            "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 (from spacy)\n",
            "  Downloading pydantic-1.8.2-py3-none-any.whl.metadata (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathlib-abc==0.1.1 (from pathy>=0.3.5->spacy)\n",
            "  Downloading pathlib_abc-0.1.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: confection<0.2.0,>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Downloading download-0.3.5-py3-none-any.whl (8.8 kB)\n",
            "Downloading es_core_news_sm-3.1.0-py3-none-any.whl (13.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spacy-3.1.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "Downloading pathy-0.11.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathlib_abc-0.1.1-py3-none-any.whl (23 kB)\n",
            "Downloading pydantic-1.8.2-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.4.2-py3-none-any.whl (27 kB)\n",
            "Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Building wheels for collected packages: thinc\n",
            "  Building wheel for thinc (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thinc: filename=thinc-8.0.17-cp311-cp311-linux_x86_64.whl size=2508594 sha256=4632ae3ef32b28c033b9f25e6bf2293a2b0729688b57fb6034a73ad48691f281\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/1d/5e/36ed7863d65cb226891461dc8a53586a0a226429f943f0e868\n",
            "Successfully built thinc\n",
            "Installing collected packages: wasabi, typer, smart-open, pydantic, pathlib-abc, blis, thinc, pathy, download, spacy, es_core_news_sm\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.3\n",
            "    Uninstalling wasabi-1.1.3:\n",
            "      Successfully uninstalled wasabi-1.1.3\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.15.2\n",
            "    Uninstalling typer-0.15.2:\n",
            "      Successfully uninstalled typer-0.15.2\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.2\n",
            "    Uninstalling pydantic-2.11.2:\n",
            "      Successfully uninstalled pydantic-2.11.2\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 1.2.1\n",
            "    Uninstalling blis-1.2.1:\n",
            "      Successfully uninstalled blis-1.2.1\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.3.4\n",
            "    Uninstalling thinc-8.3.4:\n",
            "      Successfully uninstalled thinc-8.3.4\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.8.5\n",
            "    Uninstalling spacy-3.8.5:\n",
            "      Successfully uninstalled spacy-3.8.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "openai 1.70.0 requires pydantic<3,>=1.9.0, but you have pydantic 1.8.2 which is incompatible.\n",
            "google-genai 1.9.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.8.2 which is incompatible.\n",
            "langchain-core 0.3.50 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.8.2 which is incompatible.\n",
            "langchain 0.3.22 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.8.2 which is incompatible.\n",
            "albumentations 2.0.5 requires pydantic>=2.9.2, but you have pydantic 1.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed blis-0.7.11 download-0.3.5 es_core_news_sm-3.1.0 pathlib-abc-0.1.1 pathy-0.11.0 pydantic-1.8.2 smart-open-6.4.0 spacy-3.1.7 thinc-8.0.17 typer-0.4.2 wasabi-0.10.1\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.1.7)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.8.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: download in /usr/local/lib/python3.11/dist-packages (0.3.5)\n",
            "Requirement already satisfied: en_core_web_sm in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
            "  Downloading thinc-8.3.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from download) (1.17.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Downloading blis-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
            "  Downloading pydantic-2.11.2-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Downloading spacy-3.8.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.11.2-py3-none-any.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.3/443.3 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blis-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: blis, pydantic, thinc, spacy\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.7.11\n",
            "    Uninstalling blis-0.7.11:\n",
            "      Successfully uninstalled blis-0.7.11\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.8.2\n",
            "    Uninstalling pydantic-1.8.2:\n",
            "      Successfully uninstalled pydantic-1.8.2\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.0.17\n",
            "    Uninstalling thinc-8.0.17:\n",
            "      Successfully uninstalled thinc-8.0.17\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.1.7\n",
            "    Uninstalling spacy-3.1.7:\n",
            "      Successfully uninstalled spacy-3.1.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "es-core-news-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.8.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed blis-1.3.0 pydantic-2.11.2 spacy-3.8.5 thinc-8.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **spacy**"
      ],
      "metadata": {
        "id": "9dbmZtKsoDAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "spacy es una librería de procesamiento del lenguaje natural, robusta, rápida, fácil de instalar y utilizar e integrable con otras librerías de NLP y de deep learning\n",
        "\n",
        "Tiene modelos entrenados en varios idiomas y permite realizar las típicas tareas de segmentación por oraciones, tokenizanción, análisis morfológico, extracción de entidades y análisis de opinión.\n",
        "\n",
        "Una vez instalados los modelos, podemos importarlos fácilmente:\n",
        "\n"
      ],
      "metadata": {
        "id": "dD-RWLjHoJ8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import es_core_news_sm\n",
        "import en_core_web_sm\n",
        "\n",
        "# Modelo \"pequeño\" entrenado con noticias en castellano\n",
        "# https://spacy.io/models/es\n",
        "nlp_es = es_core_news_sm.load()\n",
        "\n",
        "# Modelo \"pequeño\" entrenado con página\n",
        "# https://spacy.io/models/en\n",
        "nlp_en = en_core_web_sm.load()"
      ],
      "metadata": {
        "id": "zz38LNNYR71J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66c5d5b-db2b-414f-915f-47383d87cf9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:910: UserWarning: [W095] Model 'es_core_news_sm' (3.1.0) was trained with spaCy v3.1.0 and may not be 100% compatible with the current version (3.8.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline del modelo por defecto\n",
        "nlp_es.pipeline"
      ],
      "metadata": {
        "id": "LXM9AV6yR_FU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6df8076-366b-48f7-e724-b92bba24e9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x78f7278bbd70>),\n",
              " ('morphologizer',\n",
              "  <spacy.pipeline.morphologizer.Morphologizer at 0x78f7278bb950>),\n",
              " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x78f7c31f27a0>),\n",
              " ('attribute_ruler',\n",
              "  <spacy.pipeline.attributeruler.AttributeRuler at 0x78f727858f90>),\n",
              " ('lemmatizer',\n",
              "  <spacy.lang.es.lemmatizer.SpanishLemmatizer at 0x78f7277c9990>),\n",
              " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x78f7e9977680>)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_en.pipeline"
      ],
      "metadata": {
        "id": "_D3jzz2rSCWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45703ac1-2ec2-4de7-a647-b80256587355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x78f725dfadb0>),\n",
              " ('tagger', <spacy.pipeline.tagger.Tagger at 0x78f725df9670>),\n",
              " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x78f727890510>),\n",
              " ('attribute_ruler',\n",
              "  <spacy.pipeline.attributeruler.AttributeRuler at 0x78f7275d0d50>),\n",
              " ('lemmatizer',\n",
              "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x78f7275cb4d0>),\n",
              " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x78f7e9158820>)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvsOJmI5TUH5"
      },
      "source": [
        "Pipelines en spaCy:\n",
        "https://spacy.io/usage/processing-pipelines\n",
        "\n",
        "<img src=https://d33wubrfki0l68.cloudfront.net/16b2ccafeefd6d547171afa23f9ac62f159e353d/48b91/pipeline-7a14d4edd18f3edfee8f34393bff2992.svg width=700px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwvh9uCATUH5"
      },
      "outputs": [],
      "source": [
        "text = 'Mi nombre es Cristina y vivo en Barcelona. Hoy es lunes 17 de Junio'\n",
        "doc = nlp_es(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmkOMC-KTUH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eec91115-de8a-4e55-d33d-e68b146e6e27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mi nombre es Cristina y vivo en Barcelona. Hoy es lunes 17 de Junio\n"
          ]
        }
      ],
      "source": [
        "print(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fKMvQfQTUH6"
      },
      "source": [
        "# Tokenizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtGthRPJTUH6"
      },
      "source": [
        "## Frases"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# en el doc generado vamos a ver las frases que tienen\n",
        "for idx, sent in enumerate(doc.sents):\n",
        "    print('Frase {0:5}{1:5}'.format(str(idx), sent.text))"
      ],
      "metadata": {
        "id": "zUbj3DnVSJW2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85aecce-d5d9-47b9-8cd2-1cb9e3c569d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase 0    Mi nombre es Cristina y vivo en Barcelona.\n",
            "Frase 1    Hoy es lunes 17 de Junio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKRorfHjTUH6"
      },
      "source": [
        "## Tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#queremos ver cuales son los tokens, cuales son las palabras que hay. tambi´ne podemos verlos automaticamente, iterame sobre doc\n",
        "for idx, token in enumerate(doc):\n",
        "    print('Token {0:5}{1:5}'.format(str(idx), token.text))"
      ],
      "metadata": {
        "id": "R8QFYZziSMOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d265c8-4366-42f2-b85d-f4bff3e67732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token 0    Mi   \n",
            "Token 1    nombre\n",
            "Token 2    es   \n",
            "Token 3    Cristina\n",
            "Token 4    y    \n",
            "Token 5    vivo \n",
            "Token 6    en   \n",
            "Token 7    Barcelona\n",
            "Token 8    .    \n",
            "Token 9    Hoy  \n",
            "Token 10   es   \n",
            "Token 11   lunes\n",
            "Token 12   17   \n",
            "Token 13   de   \n",
            "Token 14   Junio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# un análisis mas detallado sobre los tokens, por ejemplo si es alfanumerico\n",
        "\n",
        "\n",
        "print('{0:10}{1:10}{2:5}'.format('Token', 'Shape', 'is_alpha'))\n",
        "for token in doc:\n",
        "    print('{0:10}{1:10}{2:5}'.format(token.text, token.shape_, str(token.is_alpha)))"
      ],
      "metadata": {
        "id": "OKiOdyoMSRHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d27fa7ee-32bf-4a3b-e6cb-029f97fe604c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token     Shape     is_alpha\n",
            "Mi        Xx        True \n",
            "nombre    xxxx      True \n",
            "es        xx        True \n",
            "Cristina  Xxxxx     True \n",
            "y         x         True \n",
            "vivo      xxxx      True \n",
            "en        xx        True \n",
            "Barcelona Xxxxx     True \n",
            ".         .         False\n",
            "Hoy       Xxx       True \n",
            "es        xx        True \n",
            "lunes     xxxx      True \n",
            "17        dd        False\n",
            "de        xx        True \n",
            "Junio     Xxxxx     True \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnFjB1N-TUH7"
      },
      "source": [
        "# Normalización de texto"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar stop words\n",
        "from spacy.lang.es.stop_words import STOP_WORDS\n",
        "\n",
        "print(list(STOP_WORDS)[:20])"
      ],
      "metadata": {
        "id": "czJ76npSSYar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa05d92-bb03-487c-90ce-981d0c38b3b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'aproximadamente', 'comentó', 'aqui', 'aquéllos', 'nuestras', 'voy', 'haces', 'mismo', 'aquel', 'dónde', 'pasado', 'largo', 'muchas', 'pudo', 'en', 'agregó', 'conmigo', 'pero', 'ahi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(STOP_WORDS))"
      ],
      "metadata": {
        "id": "ndFBu96mSk_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07d0677d-07ea-4c2a-cfd1-fddaf9e78cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "521"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_text_1 = 'Soy una frase de ejemplo de la cual vamos a eliminar los stopwords'\n",
        "[word for word in ex_text_1.lower().split() if word not in STOP_WORDS]"
      ],
      "metadata": {
        "id": "utesHnuxSlGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a85169fa-19df-46a1-fefc-347b2944e19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['frase', 'ejemplo', 'eliminar', 'stopwords']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_aszsjkTUH7"
      },
      "source": [
        "Debate: ¿Pensáis que, en general, se deben filtrar los stopwords?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_text_2 = 'No me gusta esta canción'\n",
        "[word for word in ex_text_2.lower().split() if word not in STOP_WORDS]"
      ],
      "metadata": {
        "id": "46EDFjA0Sr4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "649f3ede-3395-450d-9be8-70465629a1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gusta', 'canción']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "if 'no' in STOP_WORDS:\n",
        "  print ('Es stopword en English')"
      ],
      "metadata": {
        "id": "GjGfF1aVSuxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f35cf09d-e2cc-4874-e848-e00d4532c66c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Es stopword en English\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkbNntIATUH7"
      },
      "source": [
        "# Part of Speech tagging\n",
        "\n",
        "El PoS Tagging es una técnica **fundamental** en NLP que consiste en etiquetar cada palabra de un documento en su correspondiente categría gramatical.\n",
        "\n",
        "<img src=https://blog.aaronccwong.com/assets/images/bigram-hmm/pos-title.jpg width=650px>\n",
        "\n",
        "¿Utilidad? Muchísima:\n",
        "\n",
        "- Posibilidad de encontrar los adjetivos / sustantivos /adverbios más comunes\n",
        "- _Ayuda_ a Lemmatizers al desambiguar entre palabras\n",
        "- Grafos en los que los nodos son entidades y verbos. Posibilidad de analizar relaciones entre entidades -> Pintar ejemplo\n",
        "- Posibles features (la distribución de categorías no siempre es homogénea en función del contexto)\n",
        "\n",
        "Podríamos hacer un algoritmo que mirara verbos entre otras entidades, como nombres o adjetivos, y que fuera el verbo quien decidiera que relación tienen esas entidades. Eso se suele hacer para crear bases de datos de grafos, donde cada nodo es una entidad, y entre entidades hay relaciones.\n",
        "\n",
        "Veamos algún ejemplo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5EWLOSITUH7"
      },
      "source": [
        "Atributos (https://spacy.io/api/token#attributes):\n",
        "- pos_: tipo de palabra (sustantivo, verbo, adjetivo, etc)\n",
        "- tag_: tipo de palabra especificando más atributos\n",
        "- dep_: relación de dependencia sintáctica\n",
        "\n",
        "Explicación de los términos:\n",
        "https://github.com/explosion/spaCy/blob/master/spacy/glossary.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgfCQfIDTUH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b6f10d5-935a-4497-b363-c31b0e36e1a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mi nombre es Cristina y vivo en Barcelona. Hoy es lunes 17 de Junio"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "doc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ACCEDEMOS AL TOKEN.POS_ Para saber la etiqueta que tienen\n",
        "\n",
        "print('{0:10}{1:10}'.format('Token', 'pos'))\n",
        "for idx, token in enumerate(doc):\n",
        "    print('{0:10}{1:10}'.format(token.text, token.pos_))"
      ],
      "metadata": {
        "id": "XzzzW4DmS26q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eca4fc7-ef47-49a5-a4f6-ec0b01859f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token     pos       \n",
            "Mi        DET       \n",
            "nombre    NOUN      \n",
            "es        AUX       \n",
            "Cristina  PROPN     \n",
            "y         CCONJ     \n",
            "vivo      VERB      \n",
            "en        ADP       \n",
            "Barcelona PROPN     \n",
            ".         PUNCT     \n",
            "Hoy       ADV       \n",
            "es        AUX       \n",
            "lunes     NOUN      \n",
            "17        NUM       \n",
            "de        ADP       \n",
            "Junio     NOUN      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lo mismo la parte de los tags\n",
        "print('{0:10}{1:10}'.format('Token', 'tag'))\n",
        "for idx, token in enumerate(doc):\n",
        "    print('{0:10}{1:10}'.format(token.text, token.tag_))"
      ],
      "metadata": {
        "id": "g4hbDQVDS29E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f33b855-7649-4694-9d8c-a71890394aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token     tag       \n",
            "Mi        DET       \n",
            "nombre    NOUN      \n",
            "es        AUX       \n",
            "Cristina  PROPN     \n",
            "y         CCONJ     \n",
            "vivo      VERB      \n",
            "en        ADP       \n",
            "Barcelona PROPN     \n",
            ".         PUNCT     \n",
            "Hoy       ADV       \n",
            "es        AUX       \n",
            "lunes     NOUN      \n",
            "17        NUM       \n",
            "de        ADP       \n",
            "Junio     NOUN      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('{0:10}{1:10}{2:10}'.format('Token', 'tag','dep', 'Meaning'))\n",
        "for idx, token in enumerate(doc):\n",
        "    print('{0:10}{1:10}{2:10}'.format(token.text, token.dep_, str(spacy.explain(token.dep_))))"
      ],
      "metadata": {
        "id": "iu_KVVvRS2_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e841e2fd-458e-4825-ba9d-4d0704d42a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token     tag       dep       \n",
            "Mi        det       determiner\n",
            "nombre    nsubj     nominal subject\n",
            "es        cop       copula    \n",
            "Cristina  ROOT      root      \n",
            "y         cc        coordinating conjunction\n",
            "vivo      conj      conjunct  \n",
            "en        case      case marking\n",
            "Barcelona obl       oblique nominal\n",
            ".         punct     punctuation\n",
            "Hoy       advmod    adverbial modifier\n",
            "es        cop       copula    \n",
            "lunes     ROOT      root      \n",
            "17        compound  compound  \n",
            "de        case      case marking\n",
            "Junio     compound  compound  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juPA60ohTUH8"
      },
      "source": [
        "# Dependencia sintáctica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQeqFTelTUH8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "69ef6203-2bb7-4e16-edc5-3378df03e5ef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"es\" id=\"a083925b26164528bbc8e07113f27312-0\" class=\"displacy\" width=\"1450\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Mi</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">nombre</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">es</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">Cristina</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">y</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">vivo</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">en</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Barcelona.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">Hoy</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">es</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1050\">lunes</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1050\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">17</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">de</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1350\">Junio</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1350\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a083925b26164528bbc8e07113f27312-0-0\" stroke-width=\"2px\" d=\"M70,102.0 C70,52.0 145.0,52.0 145.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a083925b26164528bbc8e07113f27312-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,104.0 L62,92.0 78,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a083925b26164528bbc8e07113f27312-0-1\" stroke-width=\"2px\" d=\"M170,102.0 C170,2.0 350.0,2.0 350.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a083925b26164528bbc8e07113f27312-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M170,104.0 L162,92.0 178,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a083925b26164528bbc8e07113f27312-0-2\" stroke-width=\"2px\" d=\"M270,102.0 C270,52.0 345.0,52.0 345.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a083925b26164528bbc8e07113f27312-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M270,104.0 L262,92.0 278,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a083925b26164528bbc8e07113f27312-0-3\" stroke-width=\"2px\" d=\"M470,102.0 C470,52.0 545.0,52.0 545.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a083925b26164528bbc8e07113f27312-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M470,104.0 L462,92.0 478,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a083925b26164528bbc8e07113f27312-0-4\" stroke-width=\"2px\" d=\"M370,102.0 C370,2.0 550.0,2.0 550.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a083925b26164528bbc8e07113f27312-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M550.0,104.0 L558.0,92.0 542.0,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a083925b26164528bbc8e07113f27312-0-5\" stroke-width=\"2px\" d=\"M670,102.0 C670,52.0 745.0,52.0 745.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a083925b26164528bbc8e07113f27312-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M670,104.0 L662,92.0 678,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a083925b26164528bbc8e07113f27312-0-6\" stroke-width=\"2px\" d=\"M570,102.0 C570,2.0 750.0,2.0 750.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a083925b26164528bbc8e07113f27312-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,104.0 L758.0,92.0 742.0,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a083925b26164528bbc8e07113f27312-0-7\" stroke-width=\"2px\" d=\"M870,102.0 C870,2.0 1050.0,2.0 1050.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a083925b26164528bbc8e07113f27312-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M870,104.0 L862,92.0 878,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a083925b26164528bbc8e07113f27312-0-8\" stroke-width=\"2px\" d=\"M970,102.0 C970,52.0 1045.0,52.0 1045.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a083925b26164528bbc8e07113f27312-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M970,104.0 L962,92.0 978,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a083925b26164528bbc8e07113f27312-0-9\" stroke-width=\"2px\" d=\"M1070,102.0 C1070,52.0 1145.0,52.0 1145.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a083925b26164528bbc8e07113f27312-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1145.0,104.0 L1153.0,92.0 1137.0,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a083925b26164528bbc8e07113f27312-0-10\" stroke-width=\"2px\" d=\"M1270,102.0 C1270,52.0 1345.0,52.0 1345.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a083925b26164528bbc8e07113f27312-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1270,104.0 L1262,92.0 1278,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a083925b26164528bbc8e07113f27312-0-11\" stroke-width=\"2px\" d=\"M1070,102.0 C1070,2.0 1350.0,2.0 1350.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a083925b26164528bbc8e07113f27312-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1350.0,104.0 L1358.0,92.0 1342.0,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc, style='dep', jupyter=True, options={'distance':100})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOGzhUMOTUH8"
      },
      "source": [
        "# Reconocimiento de entidades nombradas (NER)\n",
        "\n",
        "El reconocimiento de entidades nombradas (Named Entity Recognition, NER, por sus siglas en inglés) trata de detectar posibles entidades nombradas y, posteriormente, clasificarlas entre un conjunto de categorías predefinidas.\n",
        "\n",
        "Ejemplos de entidades nombradas: nombres de personas, lugares, cantidades, empresas...\n",
        "\n",
        "Pero, ¿qué es exactamente una _entidad nombrada_? Según definió Saul Kripke * (filósofo y lógico) son - o deberían ser - todas aquellas entidades para las cuales existe uno - o más de uno - designador rígido. Es decir, dicha palabra / expresión se refiere a la misma cosa / entidad con independencia del contexto.\n",
        "\n",
        "<img src=https://hyscore.io/wp-content/uploads/2019/03/illustration_named_entity_recognition-1024x486-1.jpg width=700px>\n",
        "\n",
        "El rendimiento de los NER varía mucho en función del idioma en el que han sido entrenados. El rendimiento que se comienza a obtener (debido principalmente al uso de modelos de embeddings contextuales) supera al de un ser humano.\n",
        "\n",
        "Un enlace intersante: https://primer.ai/blog/a-new-state-of-the-art-for-named-entity-recognition/\n",
        "\n",
        "* _El nombrar y la necesidad_ (Saul Kripke), 1980"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_ner_1 = nlp_es('Jim compró 300 acciones de Acme Corp. en 2006')\n",
        "displacy.render(doc_ner_1, style='ent', jupyter=True, options={'distance':100})"
      ],
      "metadata": {
        "id": "UpaQZoHZTEOC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cc7d52cc-6cd3-4aaa-e90e-249cc4febfe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Jim compró 300 acciones de \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Acme Corp\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ". en 2006</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_ner_2 = nlp_en('Peter bought 300 shares of Acme Corp. in 2006')\n",
        "displacy.render(doc_ner_2, style='ent', jupyter=True, options={'distance':100})"
      ],
      "metadata": {
        "id": "yn9BADHnTEZe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "259c3035-c1e0-4af7-ef5b-4ce01514993d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Peter\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " bought \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    300\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " shares of \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Acme Corp.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2006\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_ner_2 = nlp_en('I heard that Paris Hilton stayed at the Hilton in Paris')\n",
        "displacy.render(doc_ner_2, style='ent', jupyter=True, options={'distance':100})"
      ],
      "metadata": {
        "id": "JEAVqlPfTEdH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cc0dce42-437c-469c-8423-e43e79e4ea3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I heard that \n",
              "<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Paris Hilton\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
              "</mark>\n",
              " stayed at the \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Hilton\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Paris\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('{0:10}{1:10}'.format('Token', 'Entity Label'))\n",
        "for entity in doc_ner_1.ents:\n",
        "    print('{0:10}{1:10}'.format(entity.text, entity.label_))"
      ],
      "metadata": {
        "id": "pIYbWOeyTNBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa8ff3dd-ef2f-4893-937f-2c21502c302d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token     Entity Label\n",
            "Acme Corp PER       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('{0:10}{1:10}'.format('Token', 'Entity Label'))\n",
        "for entity in doc_ner_2.ents:\n",
        "    print('{0:10}{1:10}'.format(entity.text, entity.label_))"
      ],
      "metadata": {
        "id": "9X3SDk18TND5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8725489-a37b-4463-c76f-2f0fd404203e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token     Entity Label\n",
            "Paris HiltonFAC       \n",
            "Hilton    GPE       \n",
            "Paris     GPE       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GR81bkOTTNHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EhiGqkKTUH9"
      },
      "source": [
        "# Lemmatization\n",
        "\n",
        "Técnica de normalización de textos que busca reducir las palabras a su raíz (lemma).\n",
        "\n",
        "Muy utilizado para reducir la cardinalidad del vocabulario asociando para diferentes formas flexionadas un único token ('entreno', 'entrenarás', 'entrenaría' -> 'entrenar').\n",
        "\n",
        "Aunque muy utilizados en motores de búsqueda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('{0:10}{1:10}{2:10}'.format('Token', 'Lemma', 'PoS Tag'))\n",
        "for idx, token in enumerate(doc):\n",
        "    print('{0:10}{1:10}{2:10}'.format(token.text, token.lemma_, token.pos_))"
      ],
      "metadata": {
        "id": "7ViLaBA0TVUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65a02c49-02d5-46b8-e5a4-0c556ff00556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token     Lemma     PoS Tag   \n",
            "Mi        mi        DET       \n",
            "nombre    nombre    NOUN      \n",
            "es        ser       AUX       \n",
            "Cristina  Cristina  PROPN     \n",
            "y         y         CCONJ     \n",
            "vivo      vivir     VERB      \n",
            "en        en        ADP       \n",
            "Barcelona Barcelona PROPN     \n",
            ".         .         PUNCT     \n",
            "Hoy       hoy       ADV       \n",
            "es        ser       AUX       \n",
            "lunes     lunes     NOUN      \n",
            "17        17        NUM       \n",
            "de        de        ADP       \n",
            "Junio     junio     NOUN      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = 'comer comiendo comieron comedor comeré comerá comerás'\n",
        "text_3 = 'comerás'\n",
        "doc_2 = nlp_es(text_2)\n",
        "doc_3 = nlp_es(text_3)\n",
        "\n",
        "\n",
        "print('Text 2')\n",
        "print('{0:10}{1:10}{2:10}'.format('Token', 'Lemma', 'PoS Tag'))\n",
        "for idx, token in enumerate(doc_2):\n",
        "    print('{0:10}{1:10}{2:10}'.format(token.text, token.lemma_, token.pos_))\n",
        "\n",
        "print('\\nText 3')\n",
        "print('{0:10}{1:10}{2:10}'.format('Token', 'Lemma', 'PoS Tag'))\n",
        "for idx, token in enumerate(doc_3):\n",
        "    print('{0:10}{1:10}{2:10}'.format(token.text, token.lemma_, token.pos_))"
      ],
      "metadata": {
        "id": "N66xn0jtTZUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cbd2ff4-4aac-4c8a-e488-77192c138db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 2\n",
            "Token     Lemma     PoS Tag   \n",
            "comer     comer     VERB      \n",
            "comiendo  comer     VERB      \n",
            "comieron  comer     VERB      \n",
            "comedor   comedor   NOUN      \n",
            "comeré    comeré    ADJ       \n",
            "comerá    comer     VERB      \n",
            "comerás   comerás   ADP       \n",
            "\n",
            "Text 3\n",
            "Token     Lemma     PoS Tag   \n",
            "comerás   comerás   ADP       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4DSGTaKTUH9"
      },
      "source": [
        "# Lemmatization vs Stemming\n",
        "\n",
        "Ambas tienen como objetivo reducir las palabras a su raíz léxica.\n",
        "\n",
        "- **Lemmatization**:\n",
        "\n",
        "    Tiene en consideración el análisis morfológico de las palabras. Son necesarios diccionarios completos de formas flexionadas y raíces (lemmas).\n",
        "    \n",
        "    A veces es necesario desambiguar. P. ej.: \"planta\" (planta vs plantar)\n",
        "\n",
        "<img src=https://blog.bitext.com/hs-fs/hubfs/lemma_v2.png width=500px>\n",
        "\n",
        "- **Stemming**:\n",
        "    \n",
        "    Algoritmos que mediante heurísticos / reglas tratan de reducir las palabras a una posible raíz (stem) mediante la eliminación de algunos prefijos y sufijos. Más sencillo que un lemmatizer\n",
        "    \n",
        "    No hay garantía de que el resultado sea una palabra real.\n",
        "    \n",
        "    El algoritmo más utilizado en Inglés es el de Porter que consiste en 5 fases de reducción de la palabra aplicadas de manera secuencial.\n",
        "    <img src=https://blog.bitext.com/hs-fs/hubfs/stemming_v2.png width=250px>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "81x3r5kQ5n1J"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET5fH6OyTUH-"
      },
      "source": [
        "# Similitud\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spaCy permite calcular la similitud semántica entre cualquier par de objetos de tipo Doc, Span o Token.\n",
        "\n",
        "Ojo, La similitud semántica es un concepto algo subjetivo, pero en este caso se puede entender como la probabilidad de que dos palabras aparezcan en los mismos contextos."
      ],
      "metadata": {
        "id": "LM2-fsNJW3V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U spacy && python -m spacy download es\n",
        "!pip install spacy\n",
        "!python -m spacy download es_core_news_md\n"
      ],
      "metadata": {
        "id": "yusN6xB2Dazg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a05309-e917-4d0d-b2fc-5238fe5b71a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Collecting es-core-news-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.8.0/es_core_news_md-3.8.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: es-core-news-md\n",
            "Successfully installed es-core-news-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# cargamos el modelo entrenado en español\n",
        "nlp_es_md = spacy.load(\"es_core_news_md\")"
      ],
      "metadata": {
        "id": "3HyDQCj6XOe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "cUYSeKZLTUH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2bdb32b-4ea9-472e-82fb-3b365fa799ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between word 1 and word 2: 0.743639\n",
            "Similarity between word 1 and word 3: 0.382572\n",
            "Similarity between word 2 and word 3: 0.442991\n"
          ]
        }
      ],
      "source": [
        "word_1 = nlp_es_md('verde')\n",
        "word_2 = nlp_es_md('azul')\n",
        "word_3 = nlp_es_md('mariposa')\n",
        "\n",
        "print('Similarity between word {} and word {}: {:0.6f}'.format(1, 2, word_1.similarity(word_2)))\n",
        "print('Similarity between word {} and word {}: {:0.6f}'.format(1, 3, word_1.similarity(word_3)))\n",
        "print('Similarity between word {} and word {}: {:0.6f}'.format(2, 3, word_2.similarity(word_3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v4s5tguTUH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc6af91-24d2-4d78-8f42-170e9b9a01c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between sent 1 and sent 2: 0.967596\n",
            "Similarity between sent 1 and sent 3: 0.651385\n",
            "Similarity between sent 2 and sent 3: 0.653034\n"
          ]
        }
      ],
      "source": [
        "sent_1 = nlp_es_md('me gusta el color verde')\n",
        "sent_2 = nlp_es_md('me gusta el azul')\n",
        "sent_3 = nlp_es_md('me gusta la mariposa')\n",
        "\n",
        "print('Similarity between sent {} and sent {}: {:0.6f}'.format(1, 2, sent_1.similarity(sent_2)))\n",
        "print('Similarity between sent {} and sent {}: {:0.6f}'.format(1, 3, sent_1.similarity(sent_3)))\n",
        "print('Similarity between sent {} and sent {}: {:0.6f}'.format(2, 3, sent_2.similarity(sent_3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wtIJ5aeTUH_"
      },
      "source": [
        "# El Universo de spaCy\n",
        "\n",
        "Diferentes recursos (paquetes, plugins, extensiones, etc) desarrollados por o para spaCy.\n",
        "\n",
        "https://spacy.io/universe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB6rZgJ2TUH_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGelgbgMTUH_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}